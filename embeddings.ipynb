{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'C:/Users/SASHANK/Documents/Projects/Azure-knownledge-Rag/Source'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 28\u001b[0m\n\u001b[0;32m     25\u001b[0m directory_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:/Users/SASHANK/Documents/Projects/Azure-knownledge-Rag/Source\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Update as needed\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Load all PDFs in the directory\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m documents \u001b[38;5;241m=\u001b[39m \u001b[43mload_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m documents:\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m No PDF files found in the directory. Exiting...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[2], line 13\u001b[0m, in \u001b[0;36mload_documents\u001b[1;34m(directory)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mload_documents\u001b[39m(directory):\n\u001b[0;32m     11\u001b[0m     documents \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m---> 13\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m     14\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m filename\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.pdf\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m     15\u001b[0m             file_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(directory, filename)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'C:/Users/SASHANK/Documents/Projects/Azure-knownledge-Rag/Source'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import fitz  # PyMuPDF for reading PDFs\n",
    "import faiss\n",
    "import numpy as np\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from ollama import Client\n",
    "from string import Template\n",
    "\n",
    "# ✅ Function to Load All PDFs from a Directory\n",
    "def load_documents(directory):\n",
    "    documents = []\n",
    "    \n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith('.pdf'):\n",
    "            file_path = os.path.join(directory, filename)\n",
    "\n",
    "            # Open PDF and extract text\n",
    "            with fitz.open(file_path) as doc:\n",
    "                text = \"\\n\".join([page.get_text(\"text\") for page in doc])\n",
    "                documents.append({\"filename\": filename, \"text\": text})\n",
    "    \n",
    "    return documents\n",
    "\n",
    "# ✅ Provide Directory Path Containing PDFs\n",
    "directory_path = \"C:\\Users\\SASHANK\\Documents\\Projects\\Azure-knownledge-Rag\\Source\"  # Update as needed\n",
    "\n",
    "# Load all PDFs in the directory\n",
    "documents = load_documents(directory_path)\n",
    "\n",
    "if not documents:\n",
    "    print(\" No PDF files found in the directory. Exiting...\")\n",
    "    exit()\n",
    "\n",
    "# ✅ Extract embeddings properly\n",
    "embeddings_model = HuggingFaceEmbeddings()\n",
    "\n",
    "# Extracting text for embeddings\n",
    "document_texts = [doc[\"text\"] for doc in documents]\n",
    "document_embeddings = embeddings_model.embed_documents(document_texts)  # Correct embedding call\n",
    "\n",
    "# ✅ Convert to numpy array & reshape properly\n",
    "document_embeddings = np.array(document_embeddings).astype('float32')\n",
    "document_embeddings_reshaped = document_embeddings.reshape(-1, document_embeddings.shape[-1])\n",
    "\n",
    "# ✅ FAISS Index Setup\n",
    "index = faiss.IndexFlatL2(document_embeddings_reshaped.shape[1])  \n",
    "index.add(document_embeddings_reshaped)\n",
    "\n",
    "# ✅ Retriever Class with Proper Index Checking\n",
    "class SimpleRetriever:\n",
    "    def __init__(self, index, embeddings_model):\n",
    "        self.index = index\n",
    "        self.embeddings_model = embeddings_model\n",
    "    \n",
    "    def retrieve(self, query, k=3):\n",
    "        query_embedding = self.embeddings_model.embed_query(query)\n",
    "        distances, indices = self.index.search(np.array([query_embedding]).astype('float32'), k)\n",
    "        \n",
    "        # ✅ Ensure indices are valid\n",
    "        valid_indices = [i for i in indices[0] if i < len(documents)]\n",
    "        return [documents[i] for i in valid_indices] if valid_indices else [{\"text\": \"No relevant context found.\"}]\n",
    "\n",
    "retriever = SimpleRetriever(index, embeddings_model) \n",
    "\n",
    "# ✅ Ollama Model Setup\n",
    "llm = Client()\n",
    "\n",
    "def answer_query(question):\n",
    "    # Retrieve relevant context\n",
    "    context = retriever.retrieve(question)\n",
    "    combined_context = \"\\n\".join(doc[\"text\"] for doc in context) if context else \"No relevant context found.\"\n",
    "    \n",
    "    # ✅ Ensure context is not too long\n",
    "    short_context = combined_context[:2000] if len(combined_context) > 2000 else combined_context\n",
    "\n",
    "    # ✅ Define Prompt Template\n",
    "    prompt_template = Template(\"\"\"\n",
    "    Use ONLY the context below.\n",
    "    If unsure, say \"I don't know\".\n",
    "    Keep answers under 4 sentences.\n",
    "\n",
    "    Context:\n",
    "    $context\n",
    "    Question: $question\n",
    "    Answer:\n",
    "    \"\"\")\n",
    "\n",
    "    prompt = prompt_template.substitute(context=short_context, question=question)\n",
    "\n",
    "    # ✅ Fix Chat API Call\n",
    "    response = llm.chat(\n",
    "        model=\"deepseek-r1:32b\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "\n",
    "    # ✅ Fix Response Extraction\n",
    "    return response['message']['content'].strip() if 'message' in response and 'content' in response['message'] else \"Error: No response generated.\"\n",
    "\n",
    "# ✅ Run Function\n",
    "if __name__ == \"__main__\":\n",
    "    user_question = \"What is Azure?\"\n",
    "    answer = answer_query(user_question)\n",
    "    print(\"Answer:\", answer)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
